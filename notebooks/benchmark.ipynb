{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "aaeb4ffa",
   "metadata": {},
   "source": [
    "# ** 2.Loading external stability and expression datasets ** \n",
    "\n",
    "**NESG Solubility** \n",
    "(https://loschmidt.chemi.muni.cz/soluprot/?page=download)\n",
    "* 10k proteins\n",
    "* Labels: exp, sol, uniprot id or local ID \n",
    "* Units: integer \n",
    "\n",
    "**Soluprot Solubility**\n",
    "(https://loschmidt.chemi.muni.cz/soluprot/?page=download)\n",
    "* 11k training, 3k test\n",
    "* Label: solubility, number IDs with no conversion map (has seq)\n",
    "* Unit: 0/1\n",
    "\n",
    "**Price Solubility**\n",
    "(https://pmc.ncbi.nlm.nih.gov/articles/PMC3372292/)\n",
    "* 7k proteins \n",
    "* Label: usability. uniprot id\n",
    "* Unit: 0/1\n",
    "\n",
    "**PSI Solubility** \n",
    "(https://academic.oup.com/bioinformatics/article/36/18/4691/5860015?login=false)\n",
    "* 11k proteins\n",
    "* Label: solubility, Aa0000 ID scheme (has seq)\n",
    "* Unit: 0/1\n",
    "* Note: ecoli with custom IDs, dropped for now \n",
    "\n",
    "**Meltome Stability** \n",
    "(https://meltomeatlas.proteomics.wzw.tum.de/master_meltomeatlasapp/)\n",
    "* 1M variants \n",
    "* Label: temperature, meltpoint, fold_change, uniprot id \n",
    "* Note: ecoli with custom IDs, dropped for now  \n",
    "\n",
    "**FireprotDB Stability** \n",
    "(https://loschmidt.chemi.muni.cz/fireprotdb/)\n",
    "* 53k variants\n",
    "* Label: ddG, dTm, pH, Tm, mutation_effect, uniprot id \n",
    "\n",
    "**ThermomutDB Stability**\n",
    "(https://biosig.lab.uq.edu.au/thermomutdb/downloads)\n",
    "* 12k variants\n",
    "* Label: pH, ddG, temperature, dTm, uniprot/pdb id \n",
    "* Note: these genes were not retrieved from the database due to removal from uniprotkb:  A0A410ZNC6 D0WVP7 G7LSK3 GQ884175 M5A5Y8 Q9REI6\n",
    "\n",
    "**CAFA** \n",
    "(https://www.kaggle.com/competitions/cafa-5-protein-function-prediction/code)\n",
    "* 142k variants\n",
    "\n",
    "**Novozyme**\n",
    "(https://www.kaggle.com/code/jinyuansun/eda-and-finetune-esm)\n",
    "* 31k variants\n",
    "\n",
    "**Protsol Solubility**\n",
    "(https://huggingface.co/datasets/AI4Protein/ProtSolM)\n",
    "* 71k proteins\n",
    "* Label: solubility, no ID but has sequence\n",
    "* Unit: 0/1 \n",
    "\n",
    "**MaveDB** \n",
    "- https://mavedb.org/search?target-organism-name=Escherichia+coli+K-12 \n",
    "\n",
    "**ProteinGym**\n",
    "-  \n",
    "\n",
    "**Align2023**\n",
    "- there is 4 enzymes with train.csv datasets in each folder, they all have mutation codes, some are multi- so will need to only get the single mutation code ones. they all have the sequence we will only look at beta-glucosidaseB and alphaamylase. \n",
    "\n",
    "**Prothermdb** \n",
    "- sent the email for access "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7655c17",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Align2023 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d20319fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "#we will now load \"masterdb.csv\" found under data\n",
    "import pandas as pd \n",
    "import os \n",
    "path = \"data/masterdb.tsv\"\n",
    "df = pd.read_csv(path,sep=\"\\t\")\n",
    "df.columns = (\n",
    "    df.columns\n",
    "    .str.strip()\n",
    "    .str.lower()\n",
    "    .str.replace(\" \", \"_\")\n",
    "    .str.replace(\"(\", \"\")\n",
    "    .str.replace(\")\", \"\")\n",
    "    .str.replace(\"?\", \"\")\n",
    ")\n",
    "df2 = pd.DataFrame()\n",
    "df2[\"id\"]=df[\"name\"]\n",
    "df2[\"sequence\"] = df[\"protein_sequence\"].astype(str)\n",
    "print(df2)\n",
    "\n",
    "def dftofasta(df,outfile):\n",
    "    with open(outfile,\"w\") as f:\n",
    "        for index,row in df.iterrows():\n",
    "            f.write(f\">{row['id']}\\n\")\n",
    "            f.write(f\"{row['sequence']}\\n\")\n",
    "    return outfile \n",
    "\n",
    "#dftofasta(df2,\"data/masterdb.fasta\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d23197d",
   "metadata": {},
   "outputs": [],
   "source": [
    "############################################\n",
    "#setting the paths, loading them into dataframes, and making the merged fasta file to cdhit \n",
    "############################################\n",
    "\n",
    "\n",
    "#PSI_PATH      = \"data/benchmark/sol_benchmark/PSI_Biology_solubility_trainset.csv\"\n",
    "#psi_detail_path = \"data/benchmark/sol_benchmark/PSI_all_data_esol.tab\"\n",
    "NESG_PATH     = \"data/benchmark/sol_benchmark/nesg/nesg.csv\"\n",
    "nesg_fasta_path = \"data/benchmark/sol_benchmark/nesg/nesg.fasta\"\n",
    "PRICE_PATH    = \"data/benchmark/sol_benchmark/Price_usability_trainset.csv\"\n",
    "soluprot_train_path = \"data/benchmark/sol_benchmark/soluprot_data/training_set.csv\"\n",
    "soluprot_test_path = \"data/benchmark/sol_benchmark/soluprot_data/test_set.csv\" \n",
    "soluprot_train_fasta = \"data/benchmark/sol_benchmark/soluprot_data/training_set.fasta\"\n",
    "soluprot_test_fasta = \"data/benchmark/sol_benchmark/soluprot_data/test_set.fasta\" \n",
    "#meltome_path = \"data/benchmark/stab_benchmark/meltome_cross-species.csv\"\n",
    "#meltome_fasta_path = \"data/benchmark/stab_benchmark/meltome_fasta.fasta\"\n",
    "fireprot_path = \"data/benchmark/stab_benchmark/fireprotdb_results_stability.csv\"\n",
    "thermomutdb_path = \"data/benchmark/stab_benchmark/thermomutdb.json\"\n",
    "thermomutdb_fasta = \"data/benchmark/stab_benchmark/thermomutdb.fasta\"\n",
    "protsol_train_path = \"data/benchmark/protsolm_data/protsolm_train.csv\"\n",
    "protsol_test_path = \"data/benchmark/protsolm_data/protsolm_test.csv\"\n",
    "novozyme_test_path = \"data/benchmark/novozymes-enzyme-stability-prediction/test.csv\"\n",
    "novozyme_train_path = \"data/benchmark/novozymes-enzyme-stability-prediction/train.csv\"\n",
    "novozyme_test_labels_path = \"data/benchmark/novozymes-enzyme-stability-prediction/test_labels.csv\"\n",
    "\n",
    "\n",
    "#LOAD DATASETS \n",
    "#psi = load_psi(\"data/benchmark/sol_benchmark/PSI_Biology_solubility_trainset.csv\",\"data/benchmark/sol_benchmark/PSI_all_data_esol.tab\")\n",
    "nesg = load_nesg(NESG_PATH, nesg_fasta_path) #no seq col \n",
    "price = load_price(PRICE_PATH) #fasta \n",
    "soluprot = load_soluprot(\n",
    "    soluprot_train_path,\n",
    "    soluprot_test_path,\n",
    "    soluprot_train_fasta,\n",
    "    soluprot_test_fasta    \n",
    ")\n",
    "fireprot = load_fireprot(fireprot_path) #sequence\n",
    "thermomut = load_thermomut(thermomutdb_path,thermomutdb_fasta)\n",
    "#meltome = load_meltome(meltome_path,meltome_fasta_path) \n",
    "protsolm = load_protsolm(protsol_train_path, protsol_test_path) #aa_seq\n",
    "novozymes = load_novozymes(\n",
    "    novozyme_train_path, novozyme_test_path, novozyme_test_labels_path\n",
    ")\n",
    "\n",
    "#ADD FASTA TO DATAFRAMES IF THE CSV DID NOT HAVE IT\n",
    "nesg_fasta = read_fasta_dict(nesg_fasta_path)\n",
    "nesg[\"sequence\"] = nesg[\"id\"].map(nesg_fasta)\n",
    "price[\"sequence\"] = price[\"fasta\"]\n",
    "protsolm[\"sequence\"] = protsolm[\"aa_seq\"]\n",
    "\n",
    "\n",
    "#MERGE ALL FASTA FILES FOR CD-HIT\n",
    "def fasta_merger_from_dfs(datasets, outpath):\n",
    "    with open(outpath, \"w\") as out:\n",
    "        for i, df in enumerate(datasets):\n",
    "            for idx, row in df.iterrows():\n",
    "                seq = row[\"sequence\"]\n",
    "                if seq is None or pd.isna(seq):\n",
    "                    continue\n",
    "                header = f\"{df.__class__.__name__}_{i}_{idx}\"\n",
    "                out.write(f\">{header}\\n{seq}\\n\")\n",
    "\n",
    "datasets = [nesg, price, soluprot, fireprot, protsolm,thermomut, novozymes]\n",
    "fasta_merger_from_dfs(datasets, \"allbenchmarks.fasta\")\n",
    "\n",
    "#SETTING  CANONICAL IDS\n",
    "for i, df in enumerate(datasets):\n",
    "    df[\"canonical_id\"] = [\n",
    "        f\"{df.__class__.__name__}_{i}_{idx}\" for idx in df.index\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10537c4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "############################################\n",
    "#Setting up functions \n",
    "############################################\n",
    "import pandas as pd\n",
    "import json\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import requests\n",
    "from Bio.SeqIO.FastaIO import SimpleFastaParser\n",
    "\n",
    "def read_fasta_dict(path: str):\n",
    "    seqs = {}\n",
    "    with open(path) as fh:\n",
    "        for header, seq in SimpleFastaParser(fh):\n",
    "            sid = header.split()[0].strip()\n",
    "            seqs[sid] = seq.strip()\n",
    "    return seqs\n",
    "\n",
    "def load_nesg(csv_path: str, fasta_path: str) -> pd.DataFrame:\n",
    "    df = pd.read_csv(csv_path)  # uses CSV header row directly: id, exp, sol\n",
    "    seqs = read_fasta_dict(fasta_path)\n",
    "    #\"sid\" \"usability\" \"fasta\" \n",
    "    df[\"sequence\"] = df[\"id\"].map(seqs)\n",
    "    return df \n",
    "\n",
    "def load_psi(csv_path: str, psi_detail_path: str) -> pd.DataFrame:\n",
    "    df = pd.read_csv(csv_path)                        # has sid + fasta + labels\n",
    "    psi_all = pd.read_csv(psi_detail_path, sep=\"\\t\")  # extra metadata\n",
    "\n",
    "    # merge on sid\n",
    "    df = df.merge(psi_all, on=\"sid\", how=\"left\")\n",
    "\n",
    "    # sequence is already in the \"fasta\" column\n",
    "    df[\"sequence\"] = df[\"fasta\"]\n",
    "\n",
    "    return df\n",
    "def load_price(csv_path: str) -> pd.DataFrame:\n",
    "    df = pd.read_csv(csv_path)\n",
    "    df[\"sequence\"] = df[\"fasta\"]\n",
    "    # \"sid\" \"usability\" \"fasta\" \n",
    "    return df\n",
    "\n",
    "def load_soluprot(train_csv: str, test_csv: str,\n",
    "                  train_fasta_path: str, test_fasta_path: str) -> pd.DataFrame:\n",
    "\n",
    "    # load FASTA → dict, keys exactly as in FASTA headers\n",
    "    train_fasta = read_fasta_dict(train_fasta_path)\n",
    "    test_fasta  = read_fasta_dict(test_fasta_path)\n",
    "\n",
    "    # merge FASTA dicts\n",
    "    fasta = {**train_fasta, **test_fasta}\n",
    "\n",
    "    # load CSVs\n",
    "    df1 = pd.read_csv(train_csv)\n",
    "    df2 = pd.read_csv(test_csv)\n",
    "\n",
    "    df = pd.concat([df1, df2], ignore_index=True)\n",
    "\n",
    "    # map sequences using the exact ids\n",
    "    df[\"sequence\"] = df[\"sid\"].map(fasta)\n",
    "\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "def load_meltome(csv_path: str, fasta_path: str) -> pd.DataFrame:\n",
    "    df = pd.read_csv(csv_path)\n",
    "\n",
    "    # load fasta into dict: {uniprot_id: sequence}\n",
    "    fasta = read_fasta_dict(fasta_path)\n",
    "\n",
    "    # extract uniprot prefix from Protein_ID (before \"_\")\n",
    "    df[\"uniprot_id\"] = df[\"Protein_ID\"].astype(str).apply(lambda x: x.split(\"_\")[0])\n",
    "\n",
    "    # map sequences\n",
    "    df[\"sequence\"] = df[\"uniprot_id\"].map(fasta)\n",
    "\n",
    "    return df\n",
    "\n",
    "def load_fireprot(csv_path: str) -> pd.DataFrame:\n",
    "    df = pd.read_csv(csv_path)\n",
    "    # \"uniprot_id\" \"pdb_id\" \"muutation\" \"ddG\" \"dTm\" \"pH\" \"tm\" \"mutation_effect\" \"sequence\"\n",
    "    return df \n",
    "\n",
    "def load_thermomut(json_path: str, fasta_path: str) -> pd.DataFrame:\n",
    "    # load JSON metadata\n",
    "    with open(json_path) as fh:\n",
    "        data = json.load(fh)\n",
    "    df = pd.DataFrame(data)\n",
    "\n",
    "    # load FASTA sequences\n",
    "    fasta_dict = read_fasta_dict(fasta_path)\n",
    "\n",
    "    # map UniProt → sequence\n",
    "    # JSON column is \"uniprot\"\n",
    "    df[\"sequence\"] = df[\"uniprot\"].map(fasta_dict)\n",
    "\n",
    "    # ensure required labels exist even if missing in JSON\n",
    "    for col in [\"ph\",\"ddg\",\"temperature\",\"dtm\",\"PDB_wild\",\n",
    "                \"pdb_mutant\",\"mutation_code\",\"mutated chain\",\"effect\"]:\n",
    "        if col not in df.columns:\n",
    "            df[col] = None\n",
    "\n",
    "    return df\n",
    "\n",
    "def load_protsolm(train_csv: str, test_csv: str) -> pd.DataFrame:\n",
    "    df1 = pd.read_csv(train_csv)\n",
    "    df2 = pd.read_csv(test_csv)\n",
    "    df = pd.concat([df1, df2], ignore_index=True)\n",
    "    # \"aa_seq\" \"detail\"\n",
    "    return df\n",
    "\n",
    "def fasta_merger(fasta_paths: list, outpath: str):\n",
    "    with open(outpath, \"w\") as out:\n",
    "        for path in fasta_paths:\n",
    "            with open(path) as fh:\n",
    "                for line in fh:\n",
    "                    out.write(line)\n",
    "\n",
    "def parse_cd_hit_clusters(clstr_path):\n",
    "    clusters = {}\n",
    "    current = None\n",
    "\n",
    "    with open(clstr_path) as f:\n",
    "        for line in f:\n",
    "            line = line.strip()\n",
    "            if line.startswith(\">Cluster\"):\n",
    "                current = line.split()[1]\n",
    "                clusters[current] = []\n",
    "            else:\n",
    "                # Example: \"0       50aa, >SEQ123... *\"\n",
    "                sid = line.split(\">\")[1].split(\"...\")[0]\n",
    "                clusters[current].append(sid)\n",
    "\n",
    "    return clusters\n",
    "\n",
    "def fasta_merger_from_dfs(datasets, outpath):\n",
    "    with open(outpath, \"w\") as out:\n",
    "        for i, df in enumerate(datasets):\n",
    "            for idx, row in df.iterrows():\n",
    "                seq = row[\"sequence\"]\n",
    "                if seq is None or pd.isna(seq):\n",
    "                    continue\n",
    "                header = f\"{df.__class__.__name__}_{i}_{idx}\"\n",
    "                out.write(f\">{header}\\n{seq}\\n\")\n",
    "\n",
    "def fetch_uniprot_fasta(ids, out_fasta, delay=0.15):\n",
    "    \"\"\"Fetch FASTA for many UniProt IDs with error handling.\"\"\"\n",
    "    with open(out_fasta, \"w\") as out:\n",
    "        for uid in ids:\n",
    "            url = f\"https://rest.uniprot.org/uniprotkb/{uid}.fasta\"\n",
    "            r = requests.get(url, timeout=10)\n",
    "\n",
    "            if r.status_code == 200 and r.text.startswith(\">\"):\n",
    "                out.write(r.text.strip() + \"\\n\")\n",
    "            else:\n",
    "                # write placeholder for failed fetch\n",
    "                out.write(f\">{uid}\\nFAILED_FETCH\\n\")\n",
    "\n",
    "            time.sleep(delay)  # rate-limit to avoid 500 errors\n",
    "\n",
    "\n",
    "\n",
    "def load_novozymes(train_path: str, test_path: str, test_labels_path: str) -> pd.DataFrame:\n",
    "    train_df = pd.read_csv(train_path)         # seq_id, protein_sequence, pH, Tm\n",
    "    test_df = pd.read_csv(test_path)           # seq_id, protein_sequence, pH\n",
    "    test_labels = pd.read_csv(test_labels_path)  # seq_id, Tm\n",
    "\n",
    "    # merge test with its labels\n",
    "    test_df = test_df.merge(test_labels, on=\"seq_id\", how=\"left\")\n",
    "\n",
    "    # unify column names to match your other datasets\n",
    "    train_df[\"sequence\"] = train_df[\"protein_sequence\"]\n",
    "    test_df[\"sequence\"]  = test_df[\"protein_sequence\"]\n",
    "\n",
    "    # combine train + test into one dataframe\n",
    "    df = pd.concat([train_df, test_df], ignore_index=True)\n",
    "\n",
    "    return df"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
